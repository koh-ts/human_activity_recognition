{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "human_activity_recognition_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koh-ts/human_activity_recognition/blob/master/human_activity_recognition_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRTRSiPb467j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score, cross_validate\n",
        "import pandas_profiling as pdp\n",
        "from IPython.display import HTML\n",
        "import lightgbm as lgb\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from collections import defaultdict\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EXPw16piWNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelExtractionCallback(object):\n",
        "    \"\"\"lightgbm.cv() から学習済みモデルを取り出すためのコールバックに使うクラス\n",
        "    NOTE: 非公開クラス '_CVBooster' に依存しているため将来的に動かなく恐れがある\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self._model = None\n",
        "    def __call__(self, env):\n",
        "        # _CVBooster の参照を保持する\n",
        "        self._model = env.model\n",
        "    def _assert_called_cb(self):\n",
        "        if self._model is None:\n",
        "            # コールバックが呼ばれていないときは例外にする\n",
        "            raise RuntimeError('callback has not called yet')\n",
        "    @property\n",
        "    def boosters_proxy(self):\n",
        "        self._assert_called_cb()\n",
        "        # Booster へのプロキシオブジェクトを返す\n",
        "        return self._model\n",
        "    @property\n",
        "    def raw_boosters(self):\n",
        "        self._assert_called_cb()\n",
        "        # Booster のリストを返す\n",
        "        return self._model.boosters\n",
        "    @property\n",
        "    def best_iteration(self):\n",
        "        self._assert_called_cb()\n",
        "        # Early stop したときの boosting round を返す\n",
        "        return self._model.best_iteration\n",
        "#from: https://blog.amedama.jp/entry/lightgbm-cv-model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSkUG2CA5IrL",
        "colab_type": "text"
      },
      "source": [
        "Mount your Google Drive. In this notebook, we assume that 'report2' folder is placed directly under 'My Drive'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56CkXhQu5Pe4",
        "colab_type": "code",
        "outputId": "e806444f-fb16-4e7b-ed11-3ba3eb264cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtU_Jfu15V7i",
        "colab_type": "text"
      },
      "source": [
        "Load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW4JeRSjROIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir=\"/content/drive/My Drive/report2/\"\n",
        "nsample = 3000\n",
        "\n",
        "xraw_train = pd.read_csv(root_dir+\"X_train.csv\",header=None)\n",
        "yraw_train = pd.read_csv(root_dir+\"y_train.csv\",header=None)\n",
        "xraw_test = pd.read_csv(root_dir+\"X_test.csv\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u7EGHv4rONN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(root_dir + 'corr_done.txt', 'rb') as f:\n",
        "  lis = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucraMTOCiGZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xraw_train = xraw_train.drop(lis, axis=1)\n",
        "xraw_test = xraw_test.drop(lis, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2QBDR5QfAC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_train = pd.read_csv(root_dir + \"subject_train.csv\", header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZrZH190i_vS",
        "colab_type": "code",
        "outputId": "64740712-7823-4623-cda0-aa2b855f8e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X_train = np.array(xraw_train)\n",
        "y_train = np.array(yraw_train.ix[:,0])\n",
        "X_test = np.array(xraw_test)\n",
        "subject_train = np.array(sub_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZCF5q1lvZpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subject_train.shape\n",
        "# X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6fSSOQKoqd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XTrain = X_train[:nsample,:] #use the first 3000 samples for training\n",
        "yTrain = y_train[:nsample]\n",
        "XVal = X_train[nsample:,:] #use the rests for validation\n",
        "yVal = y_train[nsample:]\n",
        "alldata = pd.concat([xraw_train, xraw_test], ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdFTg-vvReLy",
        "colab_type": "text"
      },
      "source": [
        "Train a linear SVM classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXu2aDHnvkLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "group_kfold = GroupKFold(n_splits=15)\n",
        "# for train_index, test_index in group_kfold.split(X_train, y_train, subject_train):\n",
        "#   print(type(train_index), train_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul8CyWYNRbwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e6c4ca36-30a7-4607-865a-654134038b21"
      },
      "source": [
        "print(\"Training linear SVM classifier.\")\n",
        "clf = svm.LinearSVC()\n",
        "clf.fit(XTrain,yTrain)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training linear SVM classifier.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcxQipZSyPCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "28750b4a-a83e-4e4d-93f0-6fac98d37c7f"
      },
      "source": [
        "temp = []\n",
        "models = []\n",
        "i = 0\n",
        "for train_index, val_index in group_kfold.split(X_train, y_train, subject_train):\n",
        "  print(type(train_index), train_index)\n",
        "  clf_svm = svm.LinearSVC()\n",
        "  x_svm_train, y_svm_val = X_train[train_index], y_train[train_index]\n",
        "  clf.fit(x_svm_train, y_svm_val)\n",
        "  models.append(('clf' + str(i), clf))\n",
        "  yHat_val_svm = clf.predict(X_train[val_index])\n",
        "  temp.append(yHat_val_svm)\n",
        "  i += 1"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 4723 4724 4725]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [ 321  322  323 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> [   0    1    2 ... 5077 5078 5079]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w69XkdAe3iOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f085b6c8-49f4-49c2-b1f3-7e07141a11be"
      },
      "source": [
        "models"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('clf0', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf1', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf2', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf3', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf4', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf5', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf6', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf7', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf8', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf9', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf10', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf11', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf12', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf13', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0)),\n",
              " ('clf14', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "            multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "            verbose=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXHDPbCNRsIr",
        "colab_type": "text"
      },
      "source": [
        "Evaluate training end validation scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDdidvDRRk43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51654ae0-f06f-4da2-cb3f-ae222fd212fc"
      },
      "source": [
        "yHatTrain = clf.predict(XTrain)\n",
        "yHatVal = clf.predict(XVal)\n",
        "print(\"Training score \", len((np.where(yHatTrain == yTrain))[0])*1.0/XTrain.shape[0])\n",
        "print(\"Validation score \", len((np.where(yHatVal == yVal))[0])*1.0/XVal.shape[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score  0.995\n",
            "Validation score  0.9134615384615384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVmsX7LLwY3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_set = lgb.Dataset(XTrain, yTrain)\n",
        "valid_data_set = lgb.Dataset(XVal, yVal, reference=train_data_set)\n",
        "\n",
        "params = {'boosting_type': 'gbdt',\n",
        "          'objective': 'multiclass',\n",
        "          'num_class': 7,\n",
        "          'metric': {'multi_error'},\n",
        "          'num_leaves': 16,\n",
        "          'learning_rate': 0.04,\n",
        "          'feature_fraction': 0.9, #0.9\n",
        "          'bagging_fraction': 0.8, #0.8\n",
        "          'bagging_freq': 7,\n",
        "          'num_iterations': 100}\n",
        "\n",
        "# params = {'objective': 'multiclass',\n",
        "#           'num_class': 7,\n",
        "#           'metric': {'multi_error'}}\n",
        "extraction_cb = ModelExtractionCallback()\n",
        "callbacks = [extraction_cb,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8C_QUQmacdw",
        "colab_type": "code",
        "outputId": "003b7c55-cfc3-4d97-919a-17962ba0abc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data_for_cv = lgb.Dataset(X_train, y_train)\n",
        "gbm_result = lgb.cv(params, train_data_for_cv, folds=group_kfold.split(X_train, y_train, subject_train), verbose_eval=True, callbacks=callbacks,)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:430: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1]\tcv_agg's multi_error: 0.428239 + 0.0757673\n",
            "[2]\tcv_agg's multi_error: 0.299988 + 0.0994157\n",
            "[3]\tcv_agg's multi_error: 0.197617 + 0.0867946\n",
            "[4]\tcv_agg's multi_error: 0.177381 + 0.0806545\n",
            "[5]\tcv_agg's multi_error: 0.166145 + 0.0773853\n",
            "[6]\tcv_agg's multi_error: 0.16231 + 0.0765691\n",
            "[7]\tcv_agg's multi_error: 0.152873 + 0.0723224\n",
            "[8]\tcv_agg's multi_error: 0.14696 + 0.0708099\n",
            "[9]\tcv_agg's multi_error: 0.146113 + 0.0690582\n",
            "[10]\tcv_agg's multi_error: 0.141343 + 0.0668797\n",
            "[11]\tcv_agg's multi_error: 0.137948 + 0.067708\n",
            "[12]\tcv_agg's multi_error: 0.135226 + 0.0668004\n",
            "[13]\tcv_agg's multi_error: 0.134202 + 0.0649197\n",
            "[14]\tcv_agg's multi_error: 0.132632 + 0.0666301\n",
            "[15]\tcv_agg's multi_error: 0.12988 + 0.0646183\n",
            "[16]\tcv_agg's multi_error: 0.125558 + 0.0662174\n",
            "[17]\tcv_agg's multi_error: 0.123493 + 0.0645647\n",
            "[18]\tcv_agg's multi_error: 0.121804 + 0.0635141\n",
            "[19]\tcv_agg's multi_error: 0.12156 + 0.0638884\n",
            "[20]\tcv_agg's multi_error: 0.120463 + 0.0629835\n",
            "[21]\tcv_agg's multi_error: 0.120266 + 0.062086\n",
            "[22]\tcv_agg's multi_error: 0.119257 + 0.0609209\n",
            "[23]\tcv_agg's multi_error: 0.119658 + 0.0614359\n",
            "[24]\tcv_agg's multi_error: 0.119729 + 0.0623344\n",
            "[25]\tcv_agg's multi_error: 0.11935 + 0.0631363\n",
            "[26]\tcv_agg's multi_error: 0.118588 + 0.0623518\n",
            "[27]\tcv_agg's multi_error: 0.11817 + 0.0615593\n",
            "[28]\tcv_agg's multi_error: 0.117017 + 0.0619582\n",
            "[29]\tcv_agg's multi_error: 0.115856 + 0.0614396\n",
            "[30]\tcv_agg's multi_error: 0.117941 + 0.0657933\n",
            "[31]\tcv_agg's multi_error: 0.116856 + 0.0645358\n",
            "[32]\tcv_agg's multi_error: 0.116684 + 0.0652467\n",
            "[33]\tcv_agg's multi_error: 0.115444 + 0.0646289\n",
            "[34]\tcv_agg's multi_error: 0.11413 + 0.0626104\n",
            "[35]\tcv_agg's multi_error: 0.113913 + 0.0621928\n",
            "[36]\tcv_agg's multi_error: 0.113299 + 0.0618951\n",
            "[37]\tcv_agg's multi_error: 0.113613 + 0.0628537\n",
            "[38]\tcv_agg's multi_error: 0.114119 + 0.0639007\n",
            "[39]\tcv_agg's multi_error: 0.113294 + 0.0636377\n",
            "[40]\tcv_agg's multi_error: 0.113748 + 0.0640643\n",
            "[41]\tcv_agg's multi_error: 0.11311 + 0.0641851\n",
            "[42]\tcv_agg's multi_error: 0.113698 + 0.0638672\n",
            "[43]\tcv_agg's multi_error: 0.112257 + 0.0637051\n",
            "[44]\tcv_agg's multi_error: 0.113028 + 0.0639296\n",
            "[45]\tcv_agg's multi_error: 0.112605 + 0.0632842\n",
            "[46]\tcv_agg's multi_error: 0.111231 + 0.0631375\n",
            "[47]\tcv_agg's multi_error: 0.11158 + 0.0624802\n",
            "[48]\tcv_agg's multi_error: 0.110979 + 0.0624599\n",
            "[49]\tcv_agg's multi_error: 0.110123 + 0.0616181\n",
            "[50]\tcv_agg's multi_error: 0.109687 + 0.0611804\n",
            "[51]\tcv_agg's multi_error: 0.110076 + 0.0616287\n",
            "[52]\tcv_agg's multi_error: 0.109889 + 0.0611161\n",
            "[53]\tcv_agg's multi_error: 0.110908 + 0.0615186\n",
            "[54]\tcv_agg's multi_error: 0.109831 + 0.0605818\n",
            "[55]\tcv_agg's multi_error: 0.110821 + 0.0602111\n",
            "[56]\tcv_agg's multi_error: 0.109339 + 0.0586442\n",
            "[57]\tcv_agg's multi_error: 0.109177 + 0.0582461\n",
            "[58]\tcv_agg's multi_error: 0.108933 + 0.0582197\n",
            "[59]\tcv_agg's multi_error: 0.109735 + 0.0585544\n",
            "[60]\tcv_agg's multi_error: 0.108451 + 0.0578869\n",
            "[61]\tcv_agg's multi_error: 0.108477 + 0.0580248\n",
            "[62]\tcv_agg's multi_error: 0.108052 + 0.0577847\n",
            "[63]\tcv_agg's multi_error: 0.108406 + 0.057564\n",
            "[64]\tcv_agg's multi_error: 0.108196 + 0.0577823\n",
            "[65]\tcv_agg's multi_error: 0.108004 + 0.0577887\n",
            "[66]\tcv_agg's multi_error: 0.107226 + 0.0578936\n",
            "[67]\tcv_agg's multi_error: 0.107629 + 0.0582911\n",
            "[68]\tcv_agg's multi_error: 0.107444 + 0.058502\n",
            "[69]\tcv_agg's multi_error: 0.106827 + 0.0593443\n",
            "[70]\tcv_agg's multi_error: 0.106614 + 0.0596569\n",
            "[71]\tcv_agg's multi_error: 0.10668 + 0.0599848\n",
            "[72]\tcv_agg's multi_error: 0.10498 + 0.0589609\n",
            "[73]\tcv_agg's multi_error: 0.104773 + 0.0590107\n",
            "[74]\tcv_agg's multi_error: 0.104364 + 0.058924\n",
            "[75]\tcv_agg's multi_error: 0.104216 + 0.0594412\n",
            "[76]\tcv_agg's multi_error: 0.104645 + 0.0599184\n",
            "[77]\tcv_agg's multi_error: 0.104478 + 0.0598836\n",
            "[78]\tcv_agg's multi_error: 0.104683 + 0.0600363\n",
            "[79]\tcv_agg's multi_error: 0.105059 + 0.0598425\n",
            "[80]\tcv_agg's multi_error: 0.104258 + 0.0598221\n",
            "[81]\tcv_agg's multi_error: 0.103803 + 0.0593731\n",
            "[82]\tcv_agg's multi_error: 0.103403 + 0.0596386\n",
            "[83]\tcv_agg's multi_error: 0.10345 + 0.0599765\n",
            "[84]\tcv_agg's multi_error: 0.104003 + 0.0601623\n",
            "[85]\tcv_agg's multi_error: 0.103851 + 0.0604535\n",
            "[86]\tcv_agg's multi_error: 0.103827 + 0.0597727\n",
            "[87]\tcv_agg's multi_error: 0.104429 + 0.0598807\n",
            "[88]\tcv_agg's multi_error: 0.104219 + 0.0596651\n",
            "[89]\tcv_agg's multi_error: 0.104025 + 0.059753\n",
            "[90]\tcv_agg's multi_error: 0.103805 + 0.0595555\n",
            "[91]\tcv_agg's multi_error: 0.104012 + 0.0595896\n",
            "[92]\tcv_agg's multi_error: 0.10401 + 0.0597008\n",
            "[93]\tcv_agg's multi_error: 0.104425 + 0.0600706\n",
            "[94]\tcv_agg's multi_error: 0.104008 + 0.0601177\n",
            "[95]\tcv_agg's multi_error: 0.104258 + 0.0607675\n",
            "[96]\tcv_agg's multi_error: 0.103797 + 0.0601039\n",
            "[97]\tcv_agg's multi_error: 0.104005 + 0.0601485\n",
            "[98]\tcv_agg's multi_error: 0.104015 + 0.0600811\n",
            "[99]\tcv_agg's multi_error: 0.103158 + 0.0593595\n",
            "[100]\tcv_agg's multi_error: 0.103191 + 0.0596131\n",
            "[101]\tcv_agg's multi_error: 0.102979 + 0.0596089\n",
            "[102]\tcv_agg's multi_error: 0.102781 + 0.0595466\n",
            "[103]\tcv_agg's multi_error: 0.101494 + 0.0583032\n",
            "[104]\tcv_agg's multi_error: 0.100841 + 0.0576786\n",
            "[105]\tcv_agg's multi_error: 0.100379 + 0.0573688\n",
            "[106]\tcv_agg's multi_error: 0.0997326 + 0.0570191\n",
            "[107]\tcv_agg's multi_error: 0.10012 + 0.0571797\n",
            "[108]\tcv_agg's multi_error: 0.099694 + 0.0567928\n",
            "[109]\tcv_agg's multi_error: 0.0996554 + 0.056742\n",
            "[110]\tcv_agg's multi_error: 0.0994957 + 0.0572359\n",
            "[111]\tcv_agg's multi_error: 0.0990672 + 0.0567838\n",
            "[112]\tcv_agg's multi_error: 0.0988644 + 0.0566429\n",
            "[113]\tcv_agg's multi_error: 0.0986436 + 0.056505\n",
            "[114]\tcv_agg's multi_error: 0.0981901 + 0.0557889\n",
            "[115]\tcv_agg's multi_error: 0.0983758 + 0.0556089\n",
            "[116]\tcv_agg's multi_error: 0.097746 + 0.0554273\n",
            "[117]\tcv_agg's multi_error: 0.0979537 + 0.0556971\n",
            "[118]\tcv_agg's multi_error: 0.0969261 + 0.0555018\n",
            "[119]\tcv_agg's multi_error: 0.0963039 + 0.055392\n",
            "[120]\tcv_agg's multi_error: 0.0958911 + 0.0551864\n",
            "[121]\tcv_agg's multi_error: 0.0967298 + 0.0556739\n",
            "[122]\tcv_agg's multi_error: 0.0959005 + 0.055322\n",
            "[123]\tcv_agg's multi_error: 0.0963328 + 0.0559286\n",
            "[124]\tcv_agg's multi_error: 0.0957277 + 0.0556142\n",
            "[125]\tcv_agg's multi_error: 0.0955058 + 0.0552301\n",
            "[126]\tcv_agg's multi_error: 0.0957161 + 0.0554482\n",
            "[127]\tcv_agg's multi_error: 0.0951071 + 0.0551113\n",
            "[128]\tcv_agg's multi_error: 0.0948864 + 0.0550076\n",
            "[129]\tcv_agg's multi_error: 0.0940313 + 0.0548583\n",
            "[130]\tcv_agg's multi_error: 0.0942416 + 0.0550594\n",
            "[131]\tcv_agg's multi_error: 0.0935898 + 0.0546268\n",
            "[132]\tcv_agg's multi_error: 0.0931859 + 0.0543025\n",
            "[133]\tcv_agg's multi_error: 0.0927384 + 0.0538695\n",
            "[134]\tcv_agg's multi_error: 0.0929495 + 0.0542978\n",
            "[135]\tcv_agg's multi_error: 0.092704 + 0.0540893\n",
            "[136]\tcv_agg's multi_error: 0.0929533 + 0.0545186\n",
            "[137]\tcv_agg's multi_error: 0.0927595 + 0.0546058\n",
            "[138]\tcv_agg's multi_error: 0.0927729 + 0.0545942\n",
            "[139]\tcv_agg's multi_error: 0.0925462 + 0.054222\n",
            "[140]\tcv_agg's multi_error: 0.0927283 + 0.0543466\n",
            "[141]\tcv_agg's multi_error: 0.0927528 + 0.0541709\n",
            "[142]\tcv_agg's multi_error: 0.0923375 + 0.0540922\n",
            "[143]\tcv_agg's multi_error: 0.0919247 + 0.0539106\n",
            "[144]\tcv_agg's multi_error: 0.0921454 + 0.0540421\n",
            "[145]\tcv_agg's multi_error: 0.0915482 + 0.0538019\n",
            "[146]\tcv_agg's multi_error: 0.0913661 + 0.053672\n",
            "[147]\tcv_agg's multi_error: 0.0912263 + 0.0542114\n",
            "[148]\tcv_agg's multi_error: 0.0910056 + 0.0540631\n",
            "[149]\tcv_agg's multi_error: 0.090958 + 0.0537219\n",
            "[150]\tcv_agg's multi_error: 0.0911403 + 0.0534347\n",
            "[151]\tcv_agg's multi_error: 0.0911403 + 0.0534347\n",
            "[152]\tcv_agg's multi_error: 0.0904721 + 0.0528526\n",
            "[153]\tcv_agg's multi_error: 0.090726 + 0.0531885\n",
            "[154]\tcv_agg's multi_error: 0.0905157 + 0.0529914\n",
            "[155]\tcv_agg's multi_error: 0.0899349 + 0.0527424\n",
            "[156]\tcv_agg's multi_error: 0.0899156 + 0.0526707\n",
            "[157]\tcv_agg's multi_error: 0.0900917 + 0.0525057\n",
            "[158]\tcv_agg's multi_error: 0.0894495 + 0.0518215\n",
            "[159]\tcv_agg's multi_error: 0.0894514 + 0.0522561\n",
            "[160]\tcv_agg's multi_error: 0.0896565 + 0.0524177\n",
            "[161]\tcv_agg's multi_error: 0.0887491 + 0.0513407\n",
            "[162]\tcv_agg's multi_error: 0.0889699 + 0.0514355\n",
            "[163]\tcv_agg's multi_error: 0.089175 + 0.0515893\n",
            "[164]\tcv_agg's multi_error: 0.089175 + 0.0515893\n",
            "[165]\tcv_agg's multi_error: 0.0889483 + 0.0512847\n",
            "[166]\tcv_agg's multi_error: 0.0885807 + 0.0512946\n",
            "[167]\tcv_agg's multi_error: 0.0881873 + 0.05088\n",
            "[168]\tcv_agg's multi_error: 0.0872732 + 0.0495632\n",
            "[169]\tcv_agg's multi_error: 0.0870794 + 0.0496483\n",
            "[170]\tcv_agg's multi_error: 0.0875073 + 0.0501934\n",
            "[171]\tcv_agg's multi_error: 0.0871161 + 0.0503635\n",
            "[172]\tcv_agg's multi_error: 0.087747 + 0.0507446\n",
            "[173]\tcv_agg's multi_error: 0.087347 + 0.0505525\n",
            "[174]\tcv_agg's multi_error: 0.0869441 + 0.0502752\n",
            "[175]\tcv_agg's multi_error: 0.0871492 + 0.0504533\n",
            "[176]\tcv_agg's multi_error: 0.0875391 + 0.0506151\n",
            "[177]\tcv_agg's multi_error: 0.0871211 + 0.0504017\n",
            "[178]\tcv_agg's multi_error: 0.0865027 + 0.0504976\n",
            "[179]\tcv_agg's multi_error: 0.0869372 + 0.0508218\n",
            "[180]\tcv_agg's multi_error: 0.087131 + 0.0507504\n",
            "[181]\tcv_agg's multi_error: 0.087195 + 0.0511179\n",
            "[182]\tcv_agg's multi_error: 0.0865612 + 0.0510684\n",
            "[183]\tcv_agg's multi_error: 0.0855982 + 0.0503739\n",
            "[184]\tcv_agg's multi_error: 0.0861863 + 0.0508889\n",
            "[185]\tcv_agg's multi_error: 0.0862402 + 0.0511477\n",
            "[186]\tcv_agg's multi_error: 0.0864393 + 0.0511442\n",
            "[187]\tcv_agg's multi_error: 0.0864393 + 0.0511442\n",
            "[188]\tcv_agg's multi_error: 0.0866661 + 0.0514607\n",
            "[189]\tcv_agg's multi_error: 0.0864047 + 0.0505948\n",
            "[190]\tcv_agg's multi_error: 0.0856032 + 0.0501928\n",
            "[191]\tcv_agg's multi_error: 0.0860567 + 0.050827\n",
            "[192]\tcv_agg's multi_error: 0.0858516 + 0.0506582\n",
            "[193]\tcv_agg's multi_error: 0.0856464 + 0.0501915\n",
            "[194]\tcv_agg's multi_error: 0.0859181 + 0.0507971\n",
            "[195]\tcv_agg's multi_error: 0.0856974 + 0.0507022\n",
            "[196]\tcv_agg's multi_error: 0.0855152 + 0.0505728\n",
            "[197]\tcv_agg's multi_error: 0.0857605 + 0.0504722\n",
            "[198]\tcv_agg's multi_error: 0.0857605 + 0.0504722\n",
            "[199]\tcv_agg's multi_error: 0.0855502 + 0.0503097\n",
            "[200]\tcv_agg's multi_error: 0.0855502 + 0.0503097\n",
            "[201]\tcv_agg's multi_error: 0.0857324 + 0.0504396\n",
            "[202]\tcv_agg's multi_error: 0.0859471 + 0.0503622\n",
            "[203]\tcv_agg's multi_error: 0.0861354 + 0.0502887\n",
            "[204]\tcv_agg's multi_error: 0.0857394 + 0.0503372\n",
            "[205]\tcv_agg's multi_error: 0.0855343 + 0.0501656\n",
            "[206]\tcv_agg's multi_error: 0.0850928 + 0.0498957\n",
            "[207]\tcv_agg's multi_error: 0.0850928 + 0.0498957\n",
            "[208]\tcv_agg's multi_error: 0.0848895 + 0.0501975\n",
            "[209]\tcv_agg's multi_error: 0.0849137 + 0.0502812\n",
            "[210]\tcv_agg's multi_error: 0.0846739 + 0.0498649\n",
            "[211]\tcv_agg's multi_error: 0.0844882 + 0.050095\n",
            "[212]\tcv_agg's multi_error: 0.0840883 + 0.0498936\n",
            "[213]\tcv_agg's multi_error: 0.0842766 + 0.0498157\n",
            "[214]\tcv_agg's multi_error: 0.0842555 + 0.0502604\n",
            "[215]\tcv_agg's multi_error: 0.08406 + 0.0496697\n",
            "[216]\tcv_agg's multi_error: 0.084054 + 0.0495102\n",
            "[217]\tcv_agg's multi_error: 0.0838332 + 0.0493454\n",
            "[218]\tcv_agg's multi_error: 0.0840156 + 0.0491333\n",
            "[219]\tcv_agg's multi_error: 0.0837948 + 0.048967\n",
            "[220]\tcv_agg's multi_error: 0.083974 + 0.0490092\n",
            "[221]\tcv_agg's multi_error: 0.0841791 + 0.0491786\n",
            "[222]\tcv_agg's multi_error: 0.0841791 + 0.0491786\n",
            "[223]\tcv_agg's multi_error: 0.0841731 + 0.0489744\n",
            "[224]\tcv_agg's multi_error: 0.084013 + 0.0492214\n",
            "[225]\tcv_agg's multi_error: 0.0833578 + 0.048836\n",
            "[226]\tcv_agg's multi_error: 0.0838053 + 0.0493013\n",
            "[227]\tcv_agg's multi_error: 0.083595 + 0.049113\n",
            "[228]\tcv_agg's multi_error: 0.0838027 + 0.0491081\n",
            "[229]\tcv_agg's multi_error: 0.083991 + 0.0490518\n",
            "[230]\tcv_agg's multi_error: 0.0839608 + 0.0488221\n",
            "[231]\tcv_agg's multi_error: 0.0841907 + 0.048925\n",
            "[232]\tcv_agg's multi_error: 0.0837701 + 0.048729\n",
            "[233]\tcv_agg's multi_error: 0.0837701 + 0.048729\n",
            "[234]\tcv_agg's multi_error: 0.0839734 + 0.0484227\n",
            "[235]\tcv_agg's multi_error: 0.0839734 + 0.0484227\n",
            "[236]\tcv_agg's multi_error: 0.0839734 + 0.0484227\n",
            "[237]\tcv_agg's multi_error: 0.0847884 + 0.0488926\n",
            "[238]\tcv_agg's multi_error: 0.0845833 + 0.0487248\n",
            "[239]\tcv_agg's multi_error: 0.0839221 + 0.0481701\n",
            "[240]\tcv_agg's multi_error: 0.0835197 + 0.0482393\n",
            "[241]\tcv_agg's multi_error: 0.0832574 + 0.0478944\n",
            "[242]\tcv_agg's multi_error: 0.0828514 + 0.0475881\n",
            "[243]\tcv_agg's multi_error: 0.0824415 + 0.0471129\n",
            "[244]\tcv_agg's multi_error: 0.0827007 + 0.0474932\n",
            "[245]\tcv_agg's multi_error: 0.0827007 + 0.0474932\n",
            "[246]\tcv_agg's multi_error: 0.0829058 + 0.0476735\n",
            "[247]\tcv_agg's multi_error: 0.0826955 + 0.0475027\n",
            "[248]\tcv_agg's multi_error: 0.0829163 + 0.0476178\n",
            "[249]\tcv_agg's multi_error: 0.0827241 + 0.0478757\n",
            "[250]\tcv_agg's multi_error: 0.0827241 + 0.0478757\n",
            "[251]\tcv_agg's multi_error: 0.0825034 + 0.0477603\n",
            "[252]\tcv_agg's multi_error: 0.0823032 + 0.0477734\n",
            "[253]\tcv_agg's multi_error: 0.0824884 + 0.0478911\n",
            "[254]\tcv_agg's multi_error: 0.0829299 + 0.0481808\n",
            "[255]\tcv_agg's multi_error: 0.0831237 + 0.0480982\n",
            "[256]\tcv_agg's multi_error: 0.0829185 + 0.0479205\n",
            "[257]\tcv_agg's multi_error: 0.0831107 + 0.0476621\n",
            "[258]\tcv_agg's multi_error: 0.0829004 + 0.0475061\n",
            "[259]\tcv_agg's multi_error: 0.0823083 + 0.0468786\n",
            "[260]\tcv_agg's multi_error: 0.0819241 + 0.047407\n",
            "[261]\tcv_agg's multi_error: 0.0819716 + 0.0476062\n",
            "[262]\tcv_agg's multi_error: 0.0817759 + 0.0473506\n",
            "[263]\tcv_agg's multi_error: 0.0817474 + 0.0473751\n",
            "[264]\tcv_agg's multi_error: 0.0819525 + 0.0475599\n",
            "[265]\tcv_agg's multi_error: 0.0819941 + 0.0477149\n",
            "[266]\tcv_agg's multi_error: 0.0821642 + 0.0478446\n",
            "[267]\tcv_agg's multi_error: 0.0817318 + 0.0474401\n",
            "[268]\tcv_agg's multi_error: 0.081511 + 0.0473344\n",
            "[269]\tcv_agg's multi_error: 0.081533 + 0.0475212\n",
            "[270]\tcv_agg's multi_error: 0.0813214 + 0.0473501\n",
            "[271]\tcv_agg's multi_error: 0.0813478 + 0.0474245\n",
            "[272]\tcv_agg's multi_error: 0.0815581 + 0.0475876\n",
            "[273]\tcv_agg's multi_error: 0.0819672 + 0.0476536\n",
            "[274]\tcv_agg's multi_error: 0.0819865 + 0.0477089\n",
            "[275]\tcv_agg's multi_error: 0.0817502 + 0.0476063\n",
            "[276]\tcv_agg's multi_error: 0.0819709 + 0.0477103\n",
            "[277]\tcv_agg's multi_error: 0.0815564 + 0.0476724\n",
            "[278]\tcv_agg's multi_error: 0.081196 + 0.0471626\n",
            "[279]\tcv_agg's multi_error: 0.0816165 + 0.0473511\n",
            "[280]\tcv_agg's multi_error: 0.0813958 + 0.0471672\n",
            "[281]\tcv_agg's multi_error: 0.0816165 + 0.0472738\n",
            "[282]\tcv_agg's multi_error: 0.0814313 + 0.0471301\n",
            "[283]\tcv_agg's multi_error: 0.0812098 + 0.0471723\n",
            "[284]\tcv_agg's multi_error: 0.0812098 + 0.0471723\n",
            "[285]\tcv_agg's multi_error: 0.0808329 + 0.0470228\n",
            "[286]\tcv_agg's multi_error: 0.0812098 + 0.0471723\n",
            "[287]\tcv_agg's multi_error: 0.0810316 + 0.0469636\n",
            "[288]\tcv_agg's multi_error: 0.0812148 + 0.0471771\n",
            "[289]\tcv_agg's multi_error: 0.0807837 + 0.0468981\n",
            "[290]\tcv_agg's multi_error: 0.0807821 + 0.0467073\n",
            "[291]\tcv_agg's multi_error: 0.0810028 + 0.046849\n",
            "[292]\tcv_agg's multi_error: 0.081027 + 0.0471361\n",
            "[293]\tcv_agg's multi_error: 0.0812191 + 0.0468693\n",
            "[294]\tcv_agg's multi_error: 0.0812191 + 0.0468693\n",
            "[295]\tcv_agg's multi_error: 0.0812191 + 0.0468693\n",
            "[296]\tcv_agg's multi_error: 0.0816917 + 0.0473419\n",
            "[297]\tcv_agg's multi_error: 0.0814766 + 0.0475595\n",
            "[298]\tcv_agg's multi_error: 0.0812575 + 0.0475756\n",
            "[299]\tcv_agg's multi_error: 0.0814606 + 0.0472765\n",
            "[300]\tcv_agg's multi_error: 0.0813009 + 0.0477619\n",
            "[301]\tcv_agg's multi_error: 0.0811088 + 0.0480356\n",
            "[302]\tcv_agg's multi_error: 0.0812971 + 0.0479996\n",
            "[303]\tcv_agg's multi_error: 0.0815022 + 0.048195\n",
            "[304]\tcv_agg's multi_error: 0.081723 + 0.0483744\n",
            "[305]\tcv_agg's multi_error: 0.0812815 + 0.048029\n",
            "[306]\tcv_agg's multi_error: 0.0806177 + 0.0474334\n",
            "[307]\tcv_agg's multi_error: 0.0808115 + 0.0473708\n",
            "[308]\tcv_agg's multi_error: 0.0810218 + 0.0475085\n",
            "[309]\tcv_agg's multi_error: 0.0808245 + 0.0475204\n",
            "[310]\tcv_agg's multi_error: 0.08081 + 0.0475877\n",
            "[311]\tcv_agg's multi_error: 0.080841 + 0.0477208\n",
            "[312]\tcv_agg's multi_error: 0.080841 + 0.0477208\n",
            "[313]\tcv_agg's multi_error: 0.0806203 + 0.0475502\n",
            "[314]\tcv_agg's multi_error: 0.0804152 + 0.0473329\n",
            "[315]\tcv_agg's multi_error: 0.08021 + 0.0471271\n",
            "[316]\tcv_agg's multi_error: 0.0798487 + 0.0469584\n",
            "[317]\tcv_agg's multi_error: 0.0796604 + 0.0469894\n",
            "[318]\tcv_agg's multi_error: 0.0798811 + 0.0471665\n",
            "[319]\tcv_agg's multi_error: 0.0802579 + 0.0475241\n",
            "[320]\tcv_agg's multi_error: 0.0802104 + 0.0473106\n",
            "[321]\tcv_agg's multi_error: 0.0797958 + 0.0472224\n",
            "[322]\tcv_agg's multi_error: 0.0799805 + 0.0472016\n",
            "[323]\tcv_agg's multi_error: 0.0794254 + 0.0470913\n",
            "[324]\tcv_agg's multi_error: 0.0789839 + 0.0467617\n",
            "[325]\tcv_agg's multi_error: 0.079189 + 0.0469879\n",
            "[326]\tcv_agg's multi_error: 0.079189 + 0.0469879\n",
            "[327]\tcv_agg's multi_error: 0.079189 + 0.0469879\n",
            "[328]\tcv_agg's multi_error: 0.0791942 + 0.0469377\n",
            "[329]\tcv_agg's multi_error: 0.0789839 + 0.0467617\n",
            "[330]\tcv_agg's multi_error: 0.0791612 + 0.0466672\n",
            "[331]\tcv_agg's multi_error: 0.0791942 + 0.0469377\n",
            "[332]\tcv_agg's multi_error: 0.0791952 + 0.0473589\n",
            "[333]\tcv_agg's multi_error: 0.0791952 + 0.0473589\n",
            "[334]\tcv_agg's multi_error: 0.0791952 + 0.0473589\n",
            "[335]\tcv_agg's multi_error: 0.0791952 + 0.0473589\n",
            "[336]\tcv_agg's multi_error: 0.0793744 + 0.0473691\n",
            "[337]\tcv_agg's multi_error: 0.0793744 + 0.0473691\n",
            "[338]\tcv_agg's multi_error: 0.0795507 + 0.0468666\n",
            "[339]\tcv_agg's multi_error: 0.0797715 + 0.0470136\n",
            "[340]\tcv_agg's multi_error: 0.0797715 + 0.0470136\n",
            "[341]\tcv_agg's multi_error: 0.0795893 + 0.046851\n",
            "[342]\tcv_agg's multi_error: 0.0789506 + 0.0464966\n",
            "[343]\tcv_agg's multi_error: 0.0789506 + 0.0464966\n",
            "[344]\tcv_agg's multi_error: 0.079343 + 0.0468528\n",
            "[345]\tcv_agg's multi_error: 0.0793846 + 0.0469913\n",
            "[346]\tcv_agg's multi_error: 0.0793846 + 0.0469913\n",
            "[347]\tcv_agg's multi_error: 0.0791578 + 0.0468072\n",
            "[348]\tcv_agg's multi_error: 0.0793786 + 0.0469718\n",
            "[349]\tcv_agg's multi_error: 0.0793786 + 0.0469718\n",
            "[350]\tcv_agg's multi_error: 0.0791954 + 0.046761\n",
            "[351]\tcv_agg's multi_error: 0.0791954 + 0.046761\n",
            "[352]\tcv_agg's multi_error: 0.0794162 + 0.0469412\n",
            "[353]\tcv_agg's multi_error: 0.0794162 + 0.0469412\n",
            "[354]\tcv_agg's multi_error: 0.0794162 + 0.0469412\n",
            "[355]\tcv_agg's multi_error: 0.079233 + 0.0467411\n",
            "[356]\tcv_agg's multi_error: 0.079233 + 0.0467411\n",
            "[357]\tcv_agg's multi_error: 0.0792226 + 0.0467799\n",
            "[358]\tcv_agg's multi_error: 0.0790018 + 0.0465982\n",
            "[359]\tcv_agg's multi_error: 0.0790018 + 0.0465982\n",
            "[360]\tcv_agg's multi_error: 0.0794109 + 0.0467236\n",
            "[361]\tcv_agg's multi_error: 0.0794109 + 0.0467236\n",
            "[362]\tcv_agg's multi_error: 0.0794109 + 0.0467236\n",
            "[363]\tcv_agg's multi_error: 0.0795992 + 0.0466934\n",
            "[364]\tcv_agg's multi_error: 0.0795992 + 0.0466934\n",
            "[365]\tcv_agg's multi_error: 0.0793785 + 0.0465289\n",
            "[366]\tcv_agg's multi_error: 0.0793785 + 0.0465289\n",
            "[367]\tcv_agg's multi_error: 0.0789785 + 0.0463618\n",
            "[368]\tcv_agg's multi_error: 0.078989 + 0.0463227\n",
            "[369]\tcv_agg's multi_error: 0.0789759 + 0.0461704\n",
            "[370]\tcv_agg's multi_error: 0.0789759 + 0.0461704\n",
            "[371]\tcv_agg's multi_error: 0.0789759 + 0.0461704\n",
            "[372]\tcv_agg's multi_error: 0.0789759 + 0.0461704\n",
            "[373]\tcv_agg's multi_error: 0.0793654 + 0.0463774\n",
            "[374]\tcv_agg's multi_error: 0.0791447 + 0.0462264\n",
            "[375]\tcv_agg's multi_error: 0.0793714 + 0.0464129\n",
            "[376]\tcv_agg's multi_error: 0.0793714 + 0.0464129\n",
            "[377]\tcv_agg's multi_error: 0.0793714 + 0.0464129\n",
            "[378]\tcv_agg's multi_error: 0.0791903 + 0.0466633\n",
            "[379]\tcv_agg's multi_error: 0.0795546 + 0.0466138\n",
            "[380]\tcv_agg's multi_error: 0.0795546 + 0.0466138\n",
            "[381]\tcv_agg's multi_error: 0.0795546 + 0.0466138\n",
            "[382]\tcv_agg's multi_error: 0.0791903 + 0.0466633\n",
            "[383]\tcv_agg's multi_error: 0.0795546 + 0.0466138\n",
            "[384]\tcv_agg's multi_error: 0.0789494 + 0.0470111\n",
            "[385]\tcv_agg's multi_error: 0.0791597 + 0.0472285\n",
            "[386]\tcv_agg's multi_error: 0.0787287 + 0.0468758\n",
            "[387]\tcv_agg's multi_error: 0.0787287 + 0.0468758\n",
            "[388]\tcv_agg's multi_error: 0.0789098 + 0.0466282\n",
            "[389]\tcv_agg's multi_error: 0.0789098 + 0.0466282\n",
            "[390]\tcv_agg's multi_error: 0.0791201 + 0.0468476\n",
            "[391]\tcv_agg's multi_error: 0.0791332 + 0.046982\n",
            "[392]\tcv_agg's multi_error: 0.0791332 + 0.046982\n",
            "[393]\tcv_agg's multi_error: 0.0791332 + 0.046982\n",
            "[394]\tcv_agg's multi_error: 0.0791332 + 0.046982\n",
            "[395]\tcv_agg's multi_error: 0.0791332 + 0.046982\n",
            "[396]\tcv_agg's multi_error: 0.0789411 + 0.0472632\n",
            "[397]\tcv_agg's multi_error: 0.0789411 + 0.0472632\n",
            "[398]\tcv_agg's multi_error: 0.0789411 + 0.0472632\n",
            "[399]\tcv_agg's multi_error: 0.0784996 + 0.0469925\n",
            "[400]\tcv_agg's multi_error: 0.0784996 + 0.0469769\n",
            "[401]\tcv_agg's multi_error: 0.0789236 + 0.0468181\n",
            "[402]\tcv_agg's multi_error: 0.0791443 + 0.0469682\n",
            "[403]\tcv_agg's multi_error: 0.0791443 + 0.0469682\n",
            "[404]\tcv_agg's multi_error: 0.078783 + 0.0468013\n",
            "[405]\tcv_agg's multi_error: 0.0783159 + 0.0466749\n",
            "[406]\tcv_agg's multi_error: 0.0785367 + 0.0468127\n",
            "[407]\tcv_agg's multi_error: 0.0785367 + 0.0468127\n",
            "[408]\tcv_agg's multi_error: 0.0785367 + 0.0468127\n",
            "[409]\tcv_agg's multi_error: 0.0785367 + 0.0468127\n",
            "[410]\tcv_agg's multi_error: 0.0785367 + 0.0468127\n",
            "[411]\tcv_agg's multi_error: 0.0783099 + 0.0466238\n",
            "[412]\tcv_agg's multi_error: 0.0781161 + 0.0466891\n",
            "[413]\tcv_agg's multi_error: 0.0783238 + 0.0466945\n",
            "[414]\tcv_agg's multi_error: 0.078503 + 0.0466979\n",
            "[415]\tcv_agg's multi_error: 0.0787099 + 0.0467645\n",
            "[416]\tcv_agg's multi_error: 0.0782953 + 0.0466933\n",
            "[417]\tcv_agg's multi_error: 0.0782949 + 0.04674\n",
            "[418]\tcv_agg's multi_error: 0.0784761 + 0.0464934\n",
            "[419]\tcv_agg's multi_error: 0.0784925 + 0.0464601\n",
            "[420]\tcv_agg's multi_error: 0.0783114 + 0.0467068\n",
            "[421]\tcv_agg's multi_error: 0.0780846 + 0.0465164\n",
            "[422]\tcv_agg's multi_error: 0.0780625 + 0.046565\n",
            "[423]\tcv_agg's multi_error: 0.0780625 + 0.046565\n",
            "[424]\tcv_agg's multi_error: 0.0780625 + 0.046565\n",
            "[425]\tcv_agg's multi_error: 0.0780625 + 0.046565\n",
            "[426]\tcv_agg's multi_error: 0.0778813 + 0.0468096\n",
            "[427]\tcv_agg's multi_error: 0.0780846 + 0.0465164\n",
            "[428]\tcv_agg's multi_error: 0.0780846 + 0.0465164\n",
            "[429]\tcv_agg's multi_error: 0.0780846 + 0.0465164\n",
            "[430]\tcv_agg's multi_error: 0.0784991 + 0.0466018\n",
            "[431]\tcv_agg's multi_error: 0.0782915 + 0.0465971\n",
            "[432]\tcv_agg's multi_error: 0.0782915 + 0.0465971\n",
            "[433]\tcv_agg's multi_error: 0.0781083 + 0.0463911\n",
            "[434]\tcv_agg's multi_error: 0.0779252 + 0.0461944\n",
            "[435]\tcv_agg's multi_error: 0.0783351 + 0.046582\n",
            "[436]\tcv_agg's multi_error: 0.0781775 + 0.0462219\n",
            "[437]\tcv_agg's multi_error: 0.0783606 + 0.0464175\n",
            "[438]\tcv_agg's multi_error: 0.0783606 + 0.0464175\n",
            "[439]\tcv_agg's multi_error: 0.0782104 + 0.0464835\n",
            "[440]\tcv_agg's multi_error: 0.0784372 + 0.0467065\n",
            "[441]\tcv_agg's multi_error: 0.0780331 + 0.0465628\n",
            "[442]\tcv_agg's multi_error: 0.0782434 + 0.0467722\n",
            "[443]\tcv_agg's multi_error: 0.0782434 + 0.0467722\n",
            "[444]\tcv_agg's multi_error: 0.0781998 + 0.0467434\n",
            "[445]\tcv_agg's multi_error: 0.0784265 + 0.0469653\n",
            "[446]\tcv_agg's multi_error: 0.0786097 + 0.0471675\n",
            "[447]\tcv_agg's multi_error: 0.0786097 + 0.0471675\n",
            "[448]\tcv_agg's multi_error: 0.0786097 + 0.0471675\n",
            "[449]\tcv_agg's multi_error: 0.0786097 + 0.0471675\n",
            "[450]\tcv_agg's multi_error: 0.0786097 + 0.0471675\n",
            "[451]\tcv_agg's multi_error: 0.0786097 + 0.0471675\n",
            "[452]\tcv_agg's multi_error: 0.0786342 + 0.0469831\n",
            "[453]\tcv_agg's multi_error: 0.0780331 + 0.0465628\n",
            "[454]\tcv_agg's multi_error: 0.0778393 + 0.0466391\n",
            "[455]\tcv_agg's multi_error: 0.0780214 + 0.0468092\n",
            "[456]\tcv_agg's multi_error: 0.0780214 + 0.0468092\n",
            "[457]\tcv_agg's multi_error: 0.0780214 + 0.0468092\n",
            "[458]\tcv_agg's multi_error: 0.0782599 + 0.0470711\n",
            "[459]\tcv_agg's multi_error: 0.0780496 + 0.046849\n",
            "[460]\tcv_agg's multi_error: 0.0780496 + 0.046849\n",
            "[461]\tcv_agg's multi_error: 0.078258 + 0.0467028\n",
            "[462]\tcv_agg's multi_error: 0.0778373 + 0.046296\n",
            "[463]\tcv_agg's multi_error: 0.0774498 + 0.0464347\n",
            "[464]\tcv_agg's multi_error: 0.0774498 + 0.0464347\n",
            "[465]\tcv_agg's multi_error: 0.0776309 + 0.0461899\n",
            "[466]\tcv_agg's multi_error: 0.0776309 + 0.0461899\n",
            "[467]\tcv_agg's multi_error: 0.0774478 + 0.0460013\n",
            "[468]\tcv_agg's multi_error: 0.0774478 + 0.0460013\n",
            "[469]\tcv_agg's multi_error: 0.0774193 + 0.0459995\n",
            "[470]\tcv_agg's multi_error: 0.077627 + 0.0460082\n",
            "[471]\tcv_agg's multi_error: 0.077627 + 0.0460082\n",
            "[472]\tcv_agg's multi_error: 0.0778091 + 0.0461815\n",
            "[473]\tcv_agg's multi_error: 0.0774183 + 0.0459959\n",
            "[474]\tcv_agg's multi_error: 0.0774183 + 0.0459959\n",
            "[475]\tcv_agg's multi_error: 0.0776121 + 0.0459203\n",
            "[476]\tcv_agg's multi_error: 0.0774044 + 0.0459257\n",
            "[477]\tcv_agg's multi_error: 0.0772106 + 0.0460004\n",
            "[478]\tcv_agg's multi_error: 0.0772361 + 0.0458203\n",
            "[479]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[480]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[481]\tcv_agg's multi_error: 0.0774324 + 0.046165\n",
            "[482]\tcv_agg's multi_error: 0.0774324 + 0.046165\n",
            "[483]\tcv_agg's multi_error: 0.0774324 + 0.046165\n",
            "[484]\tcv_agg's multi_error: 0.0774324 + 0.046165\n",
            "[485]\tcv_agg's multi_error: 0.0774324 + 0.046165\n",
            "[486]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[487]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[488]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[489]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[490]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[491]\tcv_agg's multi_error: 0.0772116 + 0.046004\n",
            "[492]\tcv_agg's multi_error: 0.0774054 + 0.0459293\n",
            "[493]\tcv_agg's multi_error: 0.0774054 + 0.0459293\n",
            "[494]\tcv_agg's multi_error: 0.077044 + 0.0457558\n",
            "[495]\tcv_agg's multi_error: 0.0772262 + 0.0459216\n",
            "[496]\tcv_agg's multi_error: 0.0772262 + 0.0459216\n",
            "[497]\tcv_agg's multi_error: 0.0770341 + 0.0462132\n",
            "[498]\tcv_agg's multi_error: 0.0772262 + 0.0459216\n",
            "[499]\tcv_agg's multi_error: 0.0772262 + 0.0459216\n",
            "[500]\tcv_agg's multi_error: 0.0772262 + 0.0459216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAQZjgy46d3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "632daad7-92d3-484b-f411-25a754f1d6d9"
      },
      "source": [
        "estimators = [\n",
        "        ('lgbm', lgb.LGBMClassifier(params)),\n",
        "        ('knn', KNeighborsClassifier()),\n",
        "        ('rf', RandomForestClassifier(n_estimators=100)),\n",
        "    ]\n",
        "\n",
        "accs = defaultdict(list)\n",
        "for train_index, test_index in group_kfold.split(X_train, y_train, subject_train):\n",
        "    X_train1, X_test1 = X_train[train_index], X_train[test_index]\n",
        "    y_train1, y_test1 = y_train[train_index], y_train[test_index]\n",
        "\n",
        "    # 分類器を学習する\n",
        "    voting = VotingClassifier(estimators)\n",
        "    voting.fit(X_train1, y_train1)\n",
        "\n",
        "    # アンサンブルで推論する\n",
        "    y_pred1 = voting.predict(X_test1)\n",
        "    acc = accuracy_score(y_test1, y_pred1)\n",
        "    accs['voting'].append(acc)\n",
        "\n",
        "    # 個別の分類器の性能も確認してみる\n",
        "    for name, estimator in voting.named_estimators_.items():\n",
        "        y_pred1 = estimator.predict(X_test1)\n",
        "        acc = accuracy_score(y_test1, y_pred1)\n",
        "        accs[name].append(acc)\n",
        "\n",
        "for name, acc_list in accs.items():\n",
        "    mean_acc = np.array(acc_list).mean()\n",
        "    print(name, ':', mean_acc)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-f02a5e9e65a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 分類器を学習する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvoting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# アンサンブルで推論する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, y,\n\u001b[1;32m     67\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             )\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                 raise TypeError('Training data should be Dataset instance, met {}'\n\u001b[1;32m   1531\u001b[0m                                 .format(type(train_set).__name__))\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m             \u001b[0;31m# set network if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"machines\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"workers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nodes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mparam_dict_to_str\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise TypeError('Unknown type of parameter:%s, got:%s'\n\u001b[0;32m--> 132\u001b[0;31m                             % (key, type(val).__name__))\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unknown type of parameter:boosting_type, got:dict"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtrB0mi99TkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yHat_test_voting = voting.predict(X_test)\n",
        "np.savetxt(root_dir+'result_voting.txt', yHat_test_voting)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBfnRo2AjkRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proxy = extraction_cb.boosters_proxy\n",
        "boosters = extraction_cb.raw_boosters\n",
        "best_iteration = extraction_cb.best_iteration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfSm-tSkAuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_proba_list = proxy.predict(X_test, num_iteration=best_iteration)\n",
        "y_pred_proba_avg = np.array(y_pred_proba_list).mean(axis=0)\n",
        "y_pred = np.argmax(y_pred_proba_avg, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTBUup0kkXJ",
        "colab_type": "code",
        "outputId": "4feb3c27-84a8-4def-e93d-f9fd48f6f0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_pred)\n",
        "np.savetxt(root_dir+'result_gbm_cv_500.txt', y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 4 5 ... 3 4 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1kfYgMTfYVe",
        "colab_type": "code",
        "outputId": "2ce33a4e-7081-4c85-f9d2-99f066da59a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "round_n = np.arange(len(gbm_result['multi_error-mean']))\n",
        "plt.xlabel('round')\n",
        "plt.ylabel('multi_error-mean')\n",
        "plt.plot(round_n, gbm_result['multi_error-mean'])\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCwiD3y5R4Je",
        "colab_type": "text"
      },
      "source": [
        "Predict test data and save the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzmsp6Pqb10P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lgb.plot_importance(gbm)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtsSnmSjb0HU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# yHatTest_gbm_raw = gbm.predict(X_test)\n",
        "# yHatTest_gbm = np.argmax(yHatTest_gbm_raw, axis=1)\n",
        "# np.savetxt(root_dir+'result_gbm2.txt', yHatTest_gbm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J9v1rzg467n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yHatTest = clf.predict(X_test)\n",
        "np.savetxt(root_dir+'result_svm.txt', yHatTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "562qeDL8sICl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}